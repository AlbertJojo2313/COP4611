{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00bf530",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "\n",
    "This homework asks you to perform various experiments with ensemble methods. \n",
    "\n",
    "The dataset is the same real estate dataset we previously used from:\n",
    "\n",
    "https://www.kaggle.com/datasets/mirbektoktogaraev/madrid-real-estate-market\n",
    "\n",
    "You will write code and discussion into code and text cells in this notebook. \n",
    "\n",
    "If a code block starts with TODO:, this means that you need to write something there. \n",
    "\n",
    "There are also markdown blocks with questions. Write the answers to these questions in the specified locations.\n",
    "\n",
    "Some code had been written for you to guide the project. Don't change the already written code.\n",
    "\n",
    "## Grading\n",
    "The points add up to 10. Extensive partial credit will be offered. Thus, make sure that you are at least attempting all problems. \n",
    "\n",
    "Make sure to comment your code, such that the grader can understand what different components are doing or attempting to do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a440a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.ensemble\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cba7e7",
   "metadata": {},
   "source": [
    "# A. Setup. \n",
    "\n",
    "In this project we are going to work in a multi-variable setting. \n",
    "\n",
    "This time, there are 7 explanatory variables: ``sq_mt_built``, ``n_rooms``, ``n_bathrooms``, ``is_renewal_needed``, ``is_new_development`` and ``has_fitted_wardrobes``. \n",
    "\n",
    "We will first create the training and test data while doing some minimal data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f68a641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9764, 7)\n",
      "Training data is composed of 8000 samples.\n",
      "Test data is composed of 1764 samples.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"houses_Madrid.csv\")\n",
    "#print(f\"The columns of the database {df.columns}\")\n",
    "\n",
    "xfields = [\"sq_mt_built\", \"n_rooms\", \"n_bathrooms\", \"has_individual_heating\", \\\n",
    "           \"is_renewal_needed\", \"is_new_development\", \"has_fitted_wardrobes\"]\n",
    "yfield = [\"buy_price\"]\n",
    "# print (xfields + yfield)\n",
    "dfsel = df[xfields + yfield]\n",
    "dfselnona = dfsel.dropna()\n",
    "df_shuffled = dfselnona.sample(frac=1) # shuffle the rows\n",
    "x = df_shuffled[xfields].to_numpy(dtype=np.float64)\n",
    "y = df_shuffled[yfield].to_numpy(dtype=np.float64)\n",
    "print(x.shape)\n",
    "training_data_x = x[:8000]\n",
    "training_data_y = y[:8000]\n",
    "test_data_x = x[8000:]\n",
    "test_data_y = y[8000:]\n",
    "print(f\"Training data is composed of {len(training_data_x)} samples.\")\n",
    "print(f\"Test data is composed of {len(test_data_x)} samples.\")\n",
    "# print(test_data_x[45])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395f2cfb",
   "metadata": {},
   "source": [
    "# B. Creating a linear regression multi-variable baseline. \n",
    "\n",
    "In this section we make a linear regression predictor for the multi-variable case. We also check the performance of the resulting regressor, and print the error. \n",
    "\n",
    "This part is had been done for you, such that the work does not depend on you importing parts from the previous projects. \n",
    "\n",
    "You will need to adapt this for the other models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b2cc6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House 45 with 142.0 sqmt was sold for [650000.] euros, but our system predicted 485771.25\n",
      "House 67 with 85.0 sqmt was sold for [340000.] euros, but our system predicted 399139.28\n",
      "House 170 with 48.0 sqmt was sold for [255000.] euros, but our system predicted 429230.64\n",
      "House 189 with 96.0 sqmt was sold for [170000.] euros, but our system predicted 459119.81\n",
      "House 207 with 178.0 sqmt was sold for [530000.] euros, but our system predicted 743055.71\n",
      "The mean square error of the linear regression is 388484.49 euro\n"
     ]
    }
   ],
   "source": [
    "# training the linear regressor\n",
    "regressor = sklearn.linear_model.LinearRegression()\n",
    "regressor.fit(training_data_x, training_data_y)\n",
    "# We will create the predictions yhat for every x from the training data. We will do this one at a time. This is not an efficient way to do it, but it allows you to write and debug functions that return a scalar number\n",
    "yhats = []\n",
    "for x in test_data_x:\n",
    "    yhat = regressor.predict([x])\n",
    "    yhats.append(yhat[0])\n",
    "\n",
    "# Now, print some examples of the quality of the classifier\n",
    "examples = [45, 67, 170, 189, 207]\n",
    "for i in examples:\n",
    "    x = test_data_x[i]\n",
    "    y = test_data_y[i]\n",
    "    yhat = regressor.predict([x])[0][0]\n",
    "    print(f\"House {i} with {x[0]} sqmt was sold for {y} euros, but our system predicted {yhat:.2f}\")\n",
    "\n",
    "# Now calculate the root mean square error on the resulting arrays\n",
    "error = sklearn.metrics.mean_squared_error(yhats, test_data_y, squared=False)\n",
    "print(f\"The mean square error of the linear regression is {error:.2f} euro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85113c6b",
   "metadata": {},
   "source": [
    "# P1: Random Forest using sklearn (5 points)\n",
    "\n",
    "Use the RandomForestRegressor function from sklearn to predict the prices of the house. Print the resulting error and samples, similar to the way in Section B. \n",
    "\n",
    "Experiment with the settings of the hyperparameters: n_estimators (try at least values 10, 25, 100, 200) and max_depth (try at least values 1, 2, 4, 8, 16 and None).\n",
    "\n",
    "Retain the hyperparameter value that gives you the best result. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9dcd129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters: n_estimators=200, max_depth=8, Mean Squared Error: 367109.43\n"
     ]
    }
   ],
   "source": [
    "# TODO implement here\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Define the hyperparameter\n",
    "n_estimator_values = [10,25,100,200]\n",
    "max_depth_values = [1,2,4,8,16, None]\n",
    "\n",
    "best_score = float('inf')\n",
    "best_n_estimators = None\n",
    "best_max_depth = None\n",
    "\n",
    "\n",
    "#Loop through different hyperparameter combinations\n",
    "for n_estimators in n_estimator_values:\n",
    "    for max_depth in max_depth_values:\n",
    "        #Create and train the model\n",
    "        model = RandomForestRegressor(n_estimators= n_estimators, max_depth=max_depth, random_state=42)\n",
    "        model.fit(training_data_x,training_data_y)\n",
    "\n",
    "        #Making the predictions\n",
    "        y_pred = model.predict(test_data_x)\n",
    "\n",
    "        #Calculate the mse error\n",
    "        mse = mean_squared_error(test_data_y, y_pred, squared=False)\n",
    "\n",
    "         # Print error and sample predictions\n",
    "        #print(f\"n_estimators={n_estimators}, max_depth={max_depth}, Mean Squared Error: {mse}\")\n",
    "        \n",
    "        # Check if this model is better than the current best\n",
    "        if mse < best_score:\n",
    "            best_score = mse\n",
    "            best_n_estimators = n_estimators\n",
    "            best_max_depth = max_depth\n",
    "\n",
    "print(f\"\\nBest Hyperparameters: n_estimators={best_n_estimators}, max_depth={best_max_depth}, Mean Squared Error: {best_score:.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbe6a914",
   "metadata": {},
   "source": [
    "# Questions: \n",
    "* Q: Do you find that Random Forest performs better than the previous approaches you implemented? Discuss. \n",
    "* A: Yes it does because the MSE compared to the previous approaches, the MSE is smaller compared to the previous approach.\n",
    "\n",
    "* Q: Explain the impact of the number of estimators and max tree depth hyperparameters on the accuracy. Which hyperparameter setting gives you the best value? Is this the same as the default settings in sklearn?\n",
    "\n",
    "* A:The number of estimators (trees) and the max tree depth are crucial hyperparameters in Random Forest that significantly impact accuracy. Generally, increasing the number of estimators can improve model performance up to a certain point, after which the improvement may plateau or even decrease due to overfitting.\n",
    "\n",
    "* Q: Explain the impact of the hyperparameters on the training time. \n",
    "* A: The training time in Random Forest is influenced by various factors, including the number of estimators, the size of the dataset, and the complexity of the trees (controlled by the max tree depth and other hyperparameters). Generally, increasing the number of estimators and the max tree depth tends to increase training time because it requires fitting more trees and building deeper trees. However, Random Forest training is inherently parallelizable, allowing for efficient training on multicore processors. Therefore, while increasing these hyperparameters may increase training time, it might not scale linearly with the increase in hyperparameter values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98e415f",
   "metadata": {},
   "source": [
    "# P2: AdaBoost using sklearn (5 points)\n",
    "\n",
    "Use the AdaBoost function from sklearn to predict the prices of the house. Print the resulting error and samples, similar to the way in Section B. \n",
    "\n",
    "Experiment with the settings of the hyperparameters: loss (try \"linear\", \"square\" and \"exponential) and learning_rate (try at least values 0.2, 0.5, 1 and 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa7b135a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/albertjojo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters: loss=square, learning_rate=1, Mean Squared Error: 405897.85\n"
     ]
    }
   ],
   "source": [
    "# TODO implement here\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define hyperparameter values to experiment with\n",
    "loss_values = [\"linear\", \"square\", \"exponential\"]\n",
    "learning_rate_values = [0.2, 0.5, 1, 2]\n",
    "\n",
    "best_score = float('inf')\n",
    "best_loss = None\n",
    "best_learning_rate = None\n",
    "\n",
    "#Loop through the different hyperparameter values\n",
    "for loss in loss_values:\n",
    "    for learning_rate in learning_rate_values:\n",
    "        #Create and train the model\n",
    "        model = AdaBoostRegressor(loss=loss, learning_rate=learning_rate, random_state=42)\n",
    "        model.fit(training_data_x,training_data_y)\n",
    "\n",
    "        #Mean_sqaured_error\n",
    "        mse = mean_squared_error(test_data_y, y_pred= model.predict(test_data_x), squared=False)\n",
    "        \n",
    "        # Check if this model is better than the current best\n",
    "        if mse < best_score:\n",
    "            best_score = mse\n",
    "            best_loss = loss\n",
    "            best_learning_rate = learning_rate\n",
    "\n",
    "print(f\"\\nBest Hyperparameters: loss={best_loss}, learning_rate={best_learning_rate}, Mean Squared Error: {best_score:.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "165b9e5c",
   "metadata": {},
   "source": [
    "# Questions: \n",
    "* Q: Do you find that Adaboost performs better than the previous approaches you implemented? Discuss. \n",
    "\n",
    "* A: No, Adaboost does not perform better than the previous approaches. The mean squared error (MSE) obtained using Adaboost is higher compared to the MSE obtained using other approaches.\n",
    "\n",
    "* Q: Explain the impact of the loss and the learning_rate hyperparameters on the accuracy. Which hyperparameter setting gives you the best value? Is this the same as the default settings in sklearn?\n",
    "\n",
    "* A: The loss hyperparameter in Adaboost determines the loss function to be used when updating the weights of the samples. The choices are \"linear\", \"square\", and \"exponential\". The learning_rate hyperparameter controls the contribution of each weak learner to the final combination. Lower learning rates generally result in more accurate models, but they may require more weak learners (boosting rounds) to achieve the same performance.\n",
    "\n",
    "* Q: Explain the impact of the hyperparameters on the training time. \n",
    "* A: The training time in Adaboost is influenced by various factors, including the number of weak learners (boosting rounds), the complexity of the weak learners, and the size of the dataset. Generally, increasing the number of boosting rounds and the complexity of the weak learners tends to increase training time because it requires fitting more weak learners. However, Adaboost training is sequential, meaning each weak learner is trained sequentially, which can lead to longer training times compared to parallelizable algorithms like Random Forest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5 (main, Sep 11 2023, 08:31:25) [Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "796ea677637399cb9e35d617aaeb4c330ac409f7c555a7cfe9f448c703ef032c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
